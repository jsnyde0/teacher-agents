# Task: Implement Pedagogical Master Agent (MVP)

**ID:** TASK-2024-07-26-03
**Status:** âœ… Done
**Date Created:** 2024-07-26
**Date Completed:** 2024-07-26

## Description

Implement the MVP version of the `Pedagogical Master Agent`. This agent takes the structured output from the `Onboarding Agent` (`OnboardingData`) and determines the initial pedagogical guidelines for the `Teacher Agent`, leveraging LLM capabilities based on the student's profile.

## Relevant Specifications

*   `.cursor/specs/architecture/agentic_teacher_system.md` (Section 3.2)
*   `.cursor/specs/mvp/teacher_mvp_definition.md` (Section 3.2)

## Acceptance Criteria

*   [x] Define the `PedagogicalGuidelines` Pydantic model (likely containing a single string field for the guideline text in the MVP).
*   [x] Create `src/agents/pedagogical_master_agent.py` containing the `PedagogicalGuidelines` model definition.
*   [x] Implement a `create_pedagogical_master_agent` function within `src/agents/pedagogical_master_agent.py` that sets up the agent.
*   [x] The agent configuration (`system_prompt`, `result_type`) should guide the LLM to generate appropriate guidelines based on input `OnboardingData`.
*   [x] Include a basic integration test (`tests/agents/test_pedagogical_master_agent.py`) that:
    *   Provides sample `OnboardingData` as input context.
    *   Runs the agent.
    *   Asserts that the output is a valid `PedagogicalGuidelines` instance with a non-empty guideline string.

## Learnings

*   Passing structured data (like `OnboardingData`) within the prompt context allows subsequent agents (like PMA) to leverage prior information.
*   Pydantic AI effectively generates structured output (`PedagogicalGuidelines`) even when the input is primarily context within a natural language prompt.
*   Integration tests are valuable for verifying agent behavior with specific inputs and expected output structures.
